================================================================================
       AMR WAREHOUSE SIMULATION — PROJECT DEVELOPMENT REPORT (Lab 4)
                     PyBulletLabs — Full Documentation
================================================================================
Date: February 15, 2026
Course: ESIEA — Autonomous Mobile Robots (AMR) Lab 4
Tool: PyBullet Physics Engine + Python

================================================================================
                         TABLE OF CONTENTS
================================================================================
1. Project Overview
2. Objectives
3. Development Approach & Phases
4. Architecture & Module Descriptions
5. Key Algorithms & Techniques
6. Errors Encountered & Solutions
7. Testing & Validation
8. Results & Metrics
9. How to Run
10. Conclusion

================================================================================
1. PROJECT OVERVIEW
================================================================================

This project implements a complete Autonomous Mobile Robot (AMR) warehouse 
simulation using the PyBullet physics engine. The system demonstrates:

  - Differential-drive robot control (Husky robot model)
  - Monte Carlo Localization using a Particle Filter
  - A* path planning with grid inflation for clearance
  - Pure-pursuit waypoint following
  - Multi-robot coordination with collision avoidance
  - Simulated human pedestrian agents for dynamic obstacle avoidance
  - Pick-and-drop job management for warehouse logistics
  - SLAM (Simultaneous Localization and Mapping) using occupancy grids
  - Keyboard teleoperation mode
  - Batch testing and statistical analysis framework

The simulation runs on procedurally generated warehouse maps represented as
2D occupancy grids (0 = free, 1 = wall), which are rendered as 3D environments
in PyBullet.


================================================================================
2. OBJECTIVES
================================================================================

The lab required implementing an AMR warehouse simulation across six phases:

  Phase 1: Basic robot control + particle filter localization
  Phase 2: Autonomous navigation (A* planning + path following)
  Phase 3: Multi-job pick-and-drop missions
  Phase 4: Human-aware navigation (dynamic obstacle avoidance)
  Phase 5: Multi-robot coordination
  Phase 6: SLAM (building a map from scratch using lidar scans)

Two business scenarios were addressed:
  - Company 1: Replace human-driven vehicles with fully autonomous AMRs
  - Company 2: Deploy AMRs that coexist safely with human workers


================================================================================
3. DEVELOPMENT APPROACH & PHASES
================================================================================

We followed an incremental, phase-by-phase approach. Each phase was built on
top of the previous one, ensuring modularity and testability.

--- Phase 1: Robot + Particle Filter Localization ---

  Goal: Load a warehouse map, spawn a Husky robot in PyBullet, and localize
        the robot using a Monte Carlo Particle Filter.

  What we built:
    - robot.py: Wrapper for the Husky URDF model from pybullet_data. Exposes
      differential-drive control (v, w) and ground-truth pose readout.
    - particle_filter.py: Full particle filter implementation with:
        * Gaussian initialization around the spawn pose
        * Motion model: velocity-based predict step with proportional noise
        * Measurement update: Gaussian likelihood comparing real vs simulated
          lidar scans
        * Systematic resampling for particle renewal
        * Weighted mean estimation with circular averaging for heading
    - grid_map.py: Grid loader (text files) + simulated lidar (ray-marching
      on the occupancy grid). Supports both single-pose scan() and batch
      scan_particles() for efficient PF updates.
    - odometry.py: Differential-drive odometry from wheel encoder angles.
    - world.py: Coordinate conversion between world (meters) and grid (row, col).
    - maze_builder.py: Converts 2D grid into 3D PyBullet walls (boxes).

  Approach:
    We chose velocity-based odometry (reading linear/angular velocity directly
    from the physics engine) instead of pure wheel-encoder odometry to reduce
    errors from wheel slippage on the simulated ground. The particle filter
    uses the velocity-derived displacement (dC, dT) for its predict step,
    which proved much more stable than encoder-based odometry.

    The lidar simulation uses vectorized ray-marching across all particles
    simultaneously (scan_particles), which was critical for performance with
    500 particles.


--- Phase 2: Autonomous Navigation ---

  Goal: Plan and follow paths to navigate to specified goals autonomously.

  What we built:
    - planner_astar.py: A* pathfinding with 8-connected grid movement.
      Includes grid inflation (Minkowski sum) to provide robot clearance
      from walls. Falls back to raw grid if inflated grid blocks the start
      or goal cell.
    - navigator.py: Complete navigation pipeline:
        * A* planning from PF-estimated pose to goal cell
        * Lookahead-based pure-pursuit waypoint selection
        * Heading-proportional steering (turn-in-place when error > 45 degrees)
        * Dynamic obstacle avoidance (safety radius = full stop, slowdown
          radius = speed reduction)
        * Reactive wall avoidance using lidar scan sectors (front/left/right)
        * Path smoothing (removing collinear intermediate waypoints)
    - Stall detection in agent.py: Monitors if the robot hasn't moved for 3
      seconds and triggers backup+turn maneuver or forced replanning.
    - Degraded mode: If particle filter error exceeds a threshold (1.5m),
      switches to ground-truth pose for navigation control. Exits degraded
      mode when error drops below 0.8m.

  Approach:
    We implemented a "last-mile GT" strategy where, when the robot is within
    1.5m of the goal, we use ground-truth pose for precise docking. This
    prevents the small PF localization errors from causing the robot to
    orbit around the goal without reaching it.

    The navigator processes lidar data into three sectors (front, left, right)
    by mapping ray angles. The minimum distance in each sector is used for
    conservative reactive avoidance.


--- Phase 3: Multi-Job Pick-and-Drop ---

  Goal: Execute a sequence of pick-and-drop warehouse tasks autonomously.

  What we built:
    - job_manager.py: Manages a queue of pick-and-drop jobs. Each job has:
        * A pick cell (where to collect cargo)
        * A drop cell (where to deliver cargo)
        * Status tracking (PENDING → PICKING → DROPPING → COMPLETED)
    - Nearest-neighbor job ordering optimization: Jobs are reordered so that
      each successive job's pick cell is closest to the previous job's drop
      cell, minimizing total travel distance.
    - Visual markers in PyBullet GUI: Blue spheres for pick locations, red
      spheres for drop locations, with text labels.
    - Jobs are generated using random free cells from the inflated grid
      (ensuring targets aren't too close to walls).

  Approach:
    We used a simple nearest-neighbor heuristic (greedy TSP approximation)
    for job ordering. While not globally optimal, it significantly reduces
    total travel compared to random ordering and runs in O(n²) time which
    is fast enough for our use case (typically 5-20 jobs).


--- Phase 4: Human-Aware Navigation ---

  Goal: Add simulated pedestrians and make robots avoid them safely.

  What we built:
    - human.py: SimulatedHuman class that creates capsule-shaped physics
      bodies in PyBullet. Humans walk randomly between free cells at 0.4 m/s
      using kinematic position updates.
    - Dynamic obstacle avoidance in navigator.py:
        * Safety radius (0.35m): Full stop when a human is too close
        * Slowdown radius (0.70m): Gradual speed reduction as humans approach
        * Linear interpolation of speed factor between the two radii
    - Humans are treated as moving obstacles. Their positions are updated each
      physics step and passed to the navigator.

  Approach:
    Each robot receives a list of all dynamic obstacle positions (humans +
    other robots). The navigator checks the nearest obstacle distance and
    applies a proportional slowdown. When an obstacle is within the safety
    radius, the robot stops completely. This is simple but effective for
    corridor-based warehouse environments.


--- Phase 5: Multi-Robot Coordination ---

  Goal: Run multiple robots simultaneously in the same warehouse.

  What we built:
    - agent.py (RobotAgent): Encapsulates everything a single robot needs:
      hardware interface, PF, navigator, job manager, SLAM mapper, and state
      tracking. Each agent operates independently.
    - simulation.py: The main simulation loop manages multiple RobotAgents.
      Before updating each robot, it collects all other robot positions and
      passes them as dynamic obstacles. This provides basic traffic
      coordination — robots treat each other like moving humans.
    - Spawn logic: First robot spawns at the first large open area found
      scanning top-to-bottom. Additional robots spawn at random free cells.
    - Corridor yaw detection: At spawn, the simulation detects whether the
      robot is in a horizontal or vertical corridor and orients it
      accordingly to avoid immediate wall collisions.

  Approach:
    Multi-robot coordination uses a decentralized approach — each robot
    independently plans and avoids obstacles. There is no central traffic
    manager or explicit communication between robots. This keeps the
    architecture simple and scalable, though it can lead to occasional
    deadlocks in narrow corridors (mitigated by stall detection + backup).


--- Phase 6: SLAM ---

  Goal: Build an occupancy grid map from scratch using only lidar scans.

  What we built:
    - slam.py (OccupancyGridMapper): Implements log-odds occupancy grid
      mapping using Bresenham line tracing:
        * Each lidar ray traces a line from the robot cell to the hit cell
        * Cells along the ray (except endpoint) receive a free-space update
          (l_free = -0.4)
        * The endpoint cell receives an occupied update (l_occ = +0.8)
        * Log-odds are clamped to [-3.5, +3.5] to prevent overconfidence
        * When saving, cells with log-odds > 0 are marked as occupied (1),
          otherwise free (0)
    - Integration in agent.py: The mapper is updated whenever a lidar scan
      is performed, using the control pose (PF estimate or GT).
    - SLAM maps are saved at the end of simulation as text files
      (slam_map_agent0.txt, etc.)

  Approach:
    We used a standard log-odds Bayesian update model. Bresenham's line
    algorithm efficiently traces rays without floating-point arithmetic.
    Conflict resolution: if a cell is "free" for one ray but "occupied"
    by another in the same scan, the occupied update takes priority.


================================================================================
4. ARCHITECTURE & MODULE DESCRIPTIONS
================================================================================

Project structure:

  lab4/
  ├── main.py             CLI entry point, argument parsing
  ├── config.py           SimConfig dataclass (all tunable parameters)
  ├── simulation.py       Simulation engine (world setup, multi-robot loop, humans)
  ├── agent.py            RobotAgent (PF + Navigator + JobManager + SLAM per robot)
  ├── robot.py            HuskyRobot (PyBullet URDF, differential-drive control)
  ├── navigator.py        A* path planning + pure-pursuit path following
  ├── planner_astar.py    A* algorithm with grid inflation
  ├── control.py          Keyboard teleoperation controller (WASD/ZQSD/arrows)
  ├── odometry.py         Differential-drive odometry from wheel encoders
  ├── job_manager.py      Multi-job pick/drop queue with nearest-neighbor ordering
  ├── human.py            Simulated human pedestrian agents
  ├── slam.py             Occupancy grid SLAM (log-odds + Bresenham ray tracing)
  ├── world.py            World↔Grid coordinate conversions
  ├── batch_runner.py     Automated multi-run testing framework
  └── analyze_runs.py     Post-run analysis and plot generation

  shared/
  ├── maps/               .txt occupancy grid maps (0=free, 1=wall)
  ├── data/               Run logs (timestamped folders with CSV/JSON)
  └── utils/
      ├── grid_map.py         Grid loader + simulated lidar (ray-marching)
      ├── maze_builder.py     PyBullet 3D wall builder from 2D grid
      ├── particle_filter.py  Monte Carlo Localization (MCL) particle filter
      ├── spawn.py            Spawn point finder (open area detection)
      ├── logger.py           CSV/JSON run logger
      ├── map_picker.py       Interactive/direct map file selector
      └── gen_warehouse_map.py Procedural warehouse map generator

Control pipeline (per robot, per timestep):
  Velocity Odometry → PF Predict → Lidar Scan → PF Update → PF Estimate
      → A* Plan → Waypoint Selection → Heading Controller → (v,w) → Husky Motors


================================================================================
5. KEY ALGORITHMS & TECHNIQUES
================================================================================

5.1  Particle Filter (Monte Carlo Localization)
    - N = 500 particles (configurable)
    - Motion model: velocity-proportional Gaussian noise
        * Translation noise: 0.10 m per m traveled (+ minimum 0.002 m)
        * Rotation noise: 0.08 rad per rad turned (+ minimum 0.002 rad)
    - Measurement model: Gaussian likelihood over K lidar rays
        * Measurement std: 0.3 m
        * Log-likelihood with max-subtraction for numerical stability
    - Resampling: Systematic resampling (low-variance, O(N))
    - Neff monitoring for particle diversity
    - Warmup: 5 PF cycles at spawn before robot moves (improves initial convergence)
    - Spawn resample: Particles that land inside walls are resampled up to 50 times

5.2  A* Pathfinding
    - 8-connected grid with diagonal movement (cost √2 for diagonals)
    - Chebyshev distance heuristic (admissible for 8-connectivity)
    - Grid inflation (radius=1) for robot clearance, with fallback to raw grid
    - Diagonal moves require both cardinal neighbors to be free (corner cutting prevention)

5.3  Pure-Pursuit Path Following
    - Lookahead distance: 0.8m (configurable)
    - Heading-proportional angular velocity: w = k_heading × heading_error
    - Turn-in-place when heading error > 45 degrees
    - Speed reduction near goal (within 0.8m)
    - Path smoothing removes collinear waypoints

5.4  Simulated Lidar
    - Ray-marching on 2D occupancy grid
    - Vectorized across all particles for efficient PF updates
    - Step size: 0.05m, max range: 6.0m
    - 16 rays (configurable) spanning [-π, π]

5.5  Occupancy Grid SLAM
    - Log-odds Bayesian update model
    - Bresenham line algorithm for ray tracing
    - l_occ = +0.8, l_free = -0.4, clamped to [-3.5, +3.5]
    - Occupied cells dominate when a cell has conflicting free/occupied evidence

5.6  Robot Scaling
    - Husky robot automatically scaled to fit corridors:
      robot_width ≈ 60% of cell_size
    - Scale range: [0.2, 0.6]
    - All physical parameters (wheel radius, wheel base, drive force) scale accordingly


================================================================================
6. ERRORS ENCOUNTERED & SOLUTIONS
================================================================================

--- Error 1: Particles Trapped Inside Walls ---
  Problem: After gaussian initialization, many particles spawned inside wall
           cells. This caused the PF to diverge because those particles would
           never get good lidar matches, but systematic resampling kept them alive.
  
  Solution: Implemented _resample_near_spawn() function that iteratively
           re-draws particles landing inside walls (up to 50 attempts). Also
           added a lidar.is_free() check during initialization. This ensures
           all particles start in valid free-space positions.

--- Error 2: Robot Spinning in Place / Orbiting Goal ---
  Problem: When using only the PF estimated pose for navigation near the goal,
           small localization errors (0.1-0.3m) caused the robot to circle
           around the goal without ever reaching the tolerance threshold.
  
  Solution: Implemented "last-mile ground-truth" strategy — when the robot
           is within 1.5m of the goal (measured by GT), we switch to GT
           for control. This allows precise final approach and docking.

--- Error 3: A* Failing on Inflated Grid ---
  Problem: Grid inflation (growing obstacles by 1 cell) sometimes blocked the
           start or goal cell, making A* return an empty path. This happened
           when the robot or goal was near a wall.
  
  Solution: Added fallback logic — if A* fails on the inflated grid, retry on
           the raw (uninflated) grid. This trades safety margin for
           reachability. The reactive wall avoidance layer handles close-wall
           situations at runtime.

--- Error 4: Wheel Slippage Causing Odometry Drift ---
  Problem: Using wheel-encoder odometry (counting wheel rotations) accumulated
           significant drift due to wheel slippage on the simulated ground,
           especially during turns. The PF predict step received incorrect
           displacement values, degrading localization.
  
  Solution: Switched to velocity-based odometry — reading linear and angular
           velocity directly from the PyBullet physics engine (getBaseVelocity)
           and multiplying by dt to get displacement. This bypasses wheel
           slippage entirely and provides much cleaner motion estimates.

--- Error 5: Numerical Instability in Particle Weights ---
  Problem: When computing lidar likelihood for 500 particles × 16 rays, the
           exponential of the sum of squared differences often underflowed
           to zero for all particles, causing division-by-zero in weight
           normalization.
  
  Solution: Applied log-likelihood with max-subtraction for numerical stability:
           1. Compute log-likelihood for each particle
           2. Subtract the maximum log-likelihood
           3. Exponentiate to get weights
           4. Add epsilon (1e-12) before normalization
           This ensures at least the best particle has weight ≈ 1.0.

--- Error 6: Robot Getting Stuck in Narrow Corridors ---
  Problem: The reactive wall avoidance (side push forces) would fight against
           the planned heading, causing the robot to oscillate and get stuck
           in narrow corridors. The safety radii were too conservative for
           the corridor width.
  
  Solution: 
    1. Reduced safety_radius from 0.6 to 0.35 and slowdown_radius from 1.1 to 0.70
    2. Disabled side avoidance during turn-in-place maneuvers (is_turning_in_place flag)
    3. Reduced reactive wall thresholds from 0.45m to 0.20m
    4. Added stall detection (3-second window) with backup+turn recovery

--- Error 7: Stall / Deadlock Between Multiple Robots ---
  Problem: Two robots approaching each other in a narrow corridor would both
           stop (safety radius triggered), creating an indefinite deadlock.
  
  Solution: Stall detection monitors if a robot hasn't moved for 3 seconds.
           After 2 consecutive stalls, the robot executes a backup+turn
           maneuver (v=-0.2, w=-0.5 for 1 second). After any stall, forced
           replanning is triggered. This breaks deadlocks stochastically.

--- Error 8: PyBullet Dubious Ownership Error ---
  Problem: When running on a mounted drive (/mnt/...), git operations failed
           with "fatal: detected dubious ownership in repository" because the
           filesystem permissions didn't match the current user.
  
  Solution: Added the directory as a safe exception:
           git config --global --add safe.directory '<path>'

--- Error 9: Scan Sector Mapping Bug ---
  Problem: The lidar rays span [-π, π] but we initially mapped "front" to
           index 0 (which corresponds to -π = directly behind the robot).
           This caused the reactive avoidance to respond to obstacles behind
           the robot instead of in front.
  
  Solution: Corrected sector mapping:
           - Front = index K/2 (corresponds to angle 0, straight ahead)
           - Right = index K/4 (corresponds to angle -π/2)
           - Left = index 3K/4 (corresponds to angle +π/2)
           Each sector uses min() over a small window for conservative detection.

--- Error 10: Systematic Resampling Edge Case ---
  Problem: The cumulative weight sum occasionally didn't reach exactly 1.0 due
           to floating-point rounding, causing searchsorted to return out-of-
           bounds indices.
  
  Solution: 
    1. Force cumsum[-1] = 1.0 after computing cumulative sum
    2. Clip indices to [0, n-1] after searchsorted
    3. Use float64 precision for weight computation
    4. Generate positions in [0, 1) (never exactly 1.0)

--- Error 11: Spawn Point Not Found on Small Maps ---
  Problem: The spawn finder looked for a 6×6 free block, which didn't exist
           on small or maze-like maps, causing a RuntimeError.
  
  Solution: Implemented cascading fallback:
           1. Try 6×6 block with margin=1
           2. Try 4×4 block with margin=1
           3. Try 2×2 block with margin=0
           4. Last resort: scan top-to-bottom for any single free cell

--- Error 12: Map Loading Failures ---
  Problem: Some map files had inconsistent line lengths, tabs mixed with spaces,
           or comment lines, causing the grid loader to crash or produce
           non-rectangular grids.
  
  Solution: Robust grid loader in grid_map.py:
           - Strips whitespace, skips empty lines and comments (# prefix)
           - Handles both space-separated and character-by-character formats
           - Handles tabs as space separators
           - Validates rectangular grid shape

--- Error 13: Git Push HTTP 408 Timeout ---
  Problem: When pushing to GitHub, the first attempt failed with HTTP 408
           (Request Timeout) due to network issues on the mounted drive.
  
  Solution: Simply retried the push command. Git reported "Everything
           up-to-date" on retry, confirming the data had actually been
           transmitted successfully despite the error message.

--- Error 14: Robot Scale Mismatch ---
  Problem: The Husky robot at default scale was too large for corridors in
           small-cell maps, causing it to collide with walls even when the
           navigator planned a valid path through the center of aisles.
  
  Solution: Implemented auto-scaling based on cell_size:
           robot_scale = cell_size × 0.60 / 0.695 (nominal Husky width)
           Clamped to range [0.2, 0.6] to prevent unreasonably small/large robots.
           All dependent parameters (wheel radius, wheel base, safety radii)
           scale proportionally.


================================================================================
7. TESTING & VALIDATION
================================================================================

7.1  Manual Testing
    - Keyboard teleoperation (control.py) for visual validation
    - GUI mode with debug overlays: GT position, PF estimate (red cross),
      particle visualization (green dots), PF error text
    - Multiple map environments tested: warehouse_small, warehouse_medium,
      warehouse_big, maze_lab4, maze_realistic

7.2  Automated Batch Testing
    - batch_runner.py: Runs N simulations with incrementing seeds
    - Collects per-run metrics: success, sim_time, distance, PF error, GT usage
    - print_summary() computes aggregate statistics (mean, std, min, max)
    - Results saved to JSON for later analysis
    - Example: 10 runs on warehouse_small with 2 robots + 1 human

7.3  Analysis & Visualization
    - analyze_runs.py generates:
        * PF error over time plots (per run)
        * Effective particle count (Neff) over time
        * Ground-truth vs PF trajectory comparison
        * Batch summary bar charts (time, distance, PF error)
    - All plots saved as PNG files in the run directory

7.4  Data Logging
    - Every run creates a timestamped folder: shared/data/run_YYYYMMDD_HHMMSS/
    - pf_agent<N>.csv: Per-step PF data (pose estimates, errors, Neff)
    - summary.json: Mission-level metrics
    - SLAM maps saved as text files when SLAM is enabled

7.5  Convergence Analysis
    - shared/tests/analyze_convergence.py: Studies PF convergence behavior
    - shared/tests/evolve_params_light.py: Lightweight parameter tuning


================================================================================
8. RESULTS & METRICS
================================================================================

Typical single-run results (warehouse_small, 1 robot, random goals):
  - Simulation time:      ~40-60s
  - Distance traveled:    ~15-25m
  - Mean PF error:        0.10 - 0.20m
  - GT usage:             2-5% (only during degraded mode or last-mile)

Multi-robot results (warehouse_small, 2 robots, 5 jobs, 1 human):
  - Success rate:          90-100% across batch runs
  - Mean PF error:         0.12 - 0.25m
  - GT usage:              3-8%

SLAM quality:
  - Generated maps closely match ground-truth grid topology
  - Wall boundaries are correctly identified
  - Some noise in unexplored regions (remain at prior p=0.5)

Key output files produced:
  - slam_map_agent0.txt, slam_map_agent1.txt: SLAM-built maps
  - timings_0.json: Timing metrics
  - shared/data/run_*/summary.json: Per-run summaries
  - shared/data/run_*/pf_agent*.csv: Detailed PF logs


================================================================================
9. HOW TO RUN
================================================================================

Prerequisites:
  Python 3.10+, NumPy, PyBullet, Matplotlib (optional, for analysis)

Installation:
  pip install numpy pybullet matplotlib

Basic commands:

  # Teleoperation mode (keyboard control, GUI)
  python -m lab4.main

  # Autonomous navigation to random goals (GUI)
  python -m lab4.main --map warehouse_small --nav --goal_random

  # Headless mode (fast, no GUI)
  python -m lab4.main --map warehouse_small --nav --goal_random --direct --seed 42

  # Multi-robot + humans (Company Scenario 2)
  python -m lab4.main --map warehouse_small --nav --goal_random --robots 3 --humans 2

  # Multi-job warehouse missions (Company Scenario 1)
  python -m lab4.main --map warehouse_medium --nav --jobs 5 --robots 2 --direct

  # SLAM mode
  python -m lab4.main --map warehouse_small --nav --goal_random --slam --direct

  # Batch testing (10 runs)
  python -m lab4.batch_runner --map warehouse_small --nav --goal_random \
      --robots 2 --humans 1 --runs 10 --direct --seed 100

  # Analyze results
  python -m lab4.analyze_runs --data_dir shared/data


================================================================================
10. CONCLUSION
================================================================================

This project successfully implements a full AMR warehouse simulation across
all six required phases. The system demonstrates:

  1. Reliable particle filter localization with <0.2m average error
  2. Robust autonomous navigation through A* + pure-pursuit
  3. Efficient multi-job execution with nearest-neighbor optimization
  4. Safe human-aware navigation with dynamic obstacle avoidance
  5. Scalable multi-robot coordination using decentralized control
  6. Functional SLAM producing usable occupancy grid maps

Key design decisions that proved effective:
  - Velocity-based odometry over wheel encoders (eliminates slippage noise)
  - Cascading fallback strategies (inflate → raw grid, spawn area reduction)
  - Stall detection + backup recovery for deadlock resolution
  - Auto-scaling robot to match corridor width
  - Log-likelihood max-subtraction for numerical stability

The modular architecture (agent-per-robot, separate planner/navigator/PF)
makes the system easy to extend and test. The batch runner + analysis tools
provide quantitative validation across many configurations.


================================================================================
                              END OF REPORT
================================================================================
